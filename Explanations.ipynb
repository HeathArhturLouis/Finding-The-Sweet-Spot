{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "        <b>\n",
    "            Finding the Sweet Spot: Towards a Framework for Optimal Configurations of Feature Attribution Based Explanations\n",
    "        </b>\n",
    "    </h1>\n",
    "<h2>\n",
    "    Arthur-Louis Heath <br>\n",
    "</h2>\n",
    "    <i>\n",
    "        <b>\n",
    "            Created for BSc Thesis: Computer Science and Mathematics (2021) <br>\n",
    "            Department of Computing Science<br>\n",
    "            University of Aberdeen\n",
    "        </b>\n",
    "    </i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALL DEPENDENCIES & LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/trabant/.local/lib/python3.8/site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in /home/trabant/.local/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/trabant/.local/lib/python3.8/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: sklearn in /home/trabant/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/trabant/.local/lib/python3.8/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy in /home/trabant/.local/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/trabant/.local/lib/python3.8/site-packages (from scipy) (1.18.5)\n",
      "Requirement already satisfied: lime in /home/trabant/.local/lib/python3.8/site-packages (0.2.0.1)\n",
      "Requirement already satisfied: matplotlib in /home/trabant/.local/lib/python3.8/site-packages (from lime) (3.3.2)\n",
      "Requirement already satisfied: numpy in /home/trabant/.local/lib/python3.8/site-packages (from lime) (1.18.5)\n",
      "Requirement already satisfied: scipy in /home/trabant/.local/lib/python3.8/site-packages (from lime) (1.5.3)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /home/trabant/.local/lib/python3.8/site-packages (from lime) (0.18.1)\n",
      "Requirement already satisfied: tqdm in /home/trabant/.local/lib/python3.8/site-packages (from lime) (4.61.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/trabant/.local/lib/python3.8/site-packages (from lime) (0.23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/trabant/.local/lib/python3.8/site-packages (from matplotlib->lime) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/trabant/.local/lib/python3.8/site-packages (from matplotlib->lime) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->lime) (7.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/trabant/.local/lib/python3.8/site-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/trabant/.local/lib/python3.8/site-packages (from matplotlib->lime) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib->lime) (2.7.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (0.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/trabant/.local/lib/python3.8/site-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
      "Requirement already satisfied: shap in /home/trabant/.local/lib/python3.8/site-packages (0.39.0)\n",
      "Requirement already satisfied: numpy in /home/trabant/.local/lib/python3.8/site-packages (from shap) (1.18.5)\n",
      "Requirement already satisfied: pandas in /home/trabant/.local/lib/python3.8/site-packages (from shap) (1.2.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /home/trabant/.local/lib/python3.8/site-packages (from shap) (4.61.0)\n",
      "Requirement already satisfied: numba in /home/trabant/.local/lib/python3.8/site-packages (from shap) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in /home/trabant/.local/lib/python3.8/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /home/trabant/.local/lib/python3.8/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: scikit-learn in /home/trabant/.local/lib/python3.8/site-packages (from shap) (0.23.2)\n",
      "Requirement already satisfied: scipy in /home/trabant/.local/lib/python3.8/site-packages (from shap) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas->shap) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->shap) (2019.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba->shap) (45.2.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/trabant/.local/lib/python3.8/site-packages (from numba->shap) (0.36.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->shap) (0.17.0)\n",
      "Requirement already satisfied: dice-ml in /home/trabant/.local/lib/python3.8/site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy in /home/trabant/.local/lib/python3.8/site-packages (from dice-ml) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /home/trabant/.local/lib/python3.8/site-packages (from dice-ml) (4.61.0)\n",
      "Requirement already satisfied: h5py in /home/trabant/.local/lib/python3.8/site-packages (from dice-ml) (2.10.0)\n",
      "Requirement already satisfied: pandas in /home/trabant/.local/lib/python3.8/site-packages (from dice-ml) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in /home/trabant/.local/lib/python3.8/site-packages (from dice-ml) (0.23.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py->dice-ml) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas->dice-ml) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->dice-ml) (2019.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->dice-ml) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->dice-ml) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/trabant/.local/lib/python3.8/site-packages (from scikit-learn->dice-ml) (0.17.0)\n",
      "Requirement already satisfied: jinja2 in /home/trabant/.local/lib/python3.8/site-packages (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/trabant/.local/lib/python3.8/site-packages (from jinja2) (1.1.1)\n",
      "Requirement already satisfied: num2words in /home/trabant/.local/lib/python3.8/site-packages (0.5.10)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/trabant/.local/lib/python3.8/site-packages (from num2words) (0.6.2)\n",
      "Requirement already satisfied: ipywidgets in /home/trabant/.local/lib/python3.8/site-packages (7.6.3)\n",
      "Requirement already satisfied: ipython in /home/trabant/.local/lib/python3.8/site-packages (7.18.1)\n",
      "Requirement already satisfied: notebook in /home/trabant/.local/lib/python3.8/site-packages (6.4.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/trabant/.local/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /home/trabant/.local/lib/python3.8/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/trabant/.local/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/trabant/.local/lib/python3.8/site-packages (from ipywidgets) (5.0.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/trabant/.local/lib/python3.8/site-packages (from ipywidgets) (5.5.5)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/lib/python3/dist-packages (from ipython) (4.6.0)\n",
      "Requirement already satisfied: decorator in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (0.17.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (3.0.7)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython) (45.2.0)\n",
      "Requirement already satisfied: backcall in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/trabant/.local/lib/python3.8/site-packages (from ipython) (2.7.1)\n",
      "Requirement already satisfied: argon2-cffi in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (22.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (0.10.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (4.7.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (6.1.12)\n",
      "Requirement already satisfied: prometheus-client in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (2.11.2)\n",
      "Requirement already satisfied: ipython-genutils in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (0.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (6.1)\n",
      "Requirement already satisfied: nbconvert in /home/trabant/.local/lib/python3.8/site-packages (from notebook) (6.0.7)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/trabant/.local/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/trabant/.local/lib/python3.8/site-packages (from jedi>=0.10->ipython) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /home/trabant/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/trabant/.local/lib/python3.8/site-packages (from argon2-cffi->notebook) (1.14.5)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /home/trabant/.local/lib/python3.8/site-packages (from terminado>=0.8.3->notebook) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from jupyter-client>=5.3.4->notebook) (2.7.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/trabant/.local/lib/python3.8/site-packages (from jinja2->notebook) (1.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->notebook) (0.3)\n",
      "Requirement already satisfied: defusedxml in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (0.5.3)\n",
      "Requirement already satisfied: testpath in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (0.5.0)\n",
      "Requirement already satisfied: bleach in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/trabant/.local/lib/python3.8/site-packages (from nbconvert->notebook) (1.4.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/trabant/.local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/trabant/.local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.2.0)\n",
      "Requirement already satisfied: pycparser in /home/trabant/.local/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook) (2.20)\n",
      "Requirement already satisfied: async-generator in /home/trabant/.local/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /home/trabant/.local/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /home/trabant/.local/lib/python3.8/site-packages (from bleach->nbconvert->notebook) (0.5.1)\n",
      "Requirement already satisfied: packaging in /home/trabant/.local/lib/python3.8/site-packages (from bleach->nbconvert->notebook) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/trabant/.local/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "###### INSTALL DEPENDENCIES #######\n",
    "!python3 -m pip install numpy\n",
    "!python3 -m pip install pandas\n",
    "!python3 -m pip install sklearn\n",
    "!python3 -m pip install scipy\n",
    "!python3 -m pip install lime\n",
    "!python3 -m pip install shap\n",
    "!python3 -m pip install dice-ml\n",
    "!python3 -m pip install jinja2\n",
    "!python3 -m pip install num2words\n",
    "!python3 -m pip install ipywidgets ipython notebook \n",
    "\n",
    "\n",
    "# Alternatively use this as required\n",
    "#!python -m pip install numpy\n",
    "#!python -m pip install pandas\n",
    "#!python -m pip install sklearn\n",
    "#!python -m pip install scipy\n",
    "#!python -m pip install lime\n",
    "#!python -m pip install shap\n",
    "#!python -m pip install dice-ml\n",
    "#!python -m pip install jinja2\n",
    "#!python -m pip install num2words\n",
    "#!python -m pip install ipywidgets ipython notebook \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ipywidgets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfa5afaa78b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ipywidgets"
     ]
    }
   ],
   "source": [
    "###### LOAD LIBRARIES #######\n",
    "\n",
    "#from dataclasses import dataclass\n",
    "\n",
    "# Jupyter\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Explainability Tools\n",
    "\n",
    "## LIME\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "## SHAP\n",
    "import shap\n",
    "\n",
    "## Global Linear Approximation (Linear Regression)\n",
    "from sklearn import linear_model\n",
    "\n",
    "## DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "\n",
    "\n",
    "# Natural Language Generation\n",
    "from jinja2 import Template, FileSystemLoader, Environment\n",
    "from num2words import num2words\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm, rc, gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "## Analytics Vidhya Loan Approval Dataset\n",
    "## Source: https://www.kaggle.com/leonbora/analytics-vidhya-loan-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "orig_dataset = pd.read_csv('loan_appproval_dataset.csv')\n",
    "orig_dataset = orig_dataset.drop(columns=['Loan_ID'])\n",
    "orig_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values (EG LoanAmount = NaN)\n",
    "\n",
    "orig_dataset = orig_dataset.dropna()\n",
    "\n",
    "orig_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify feature names for display\n",
    "\n",
    "pretty_names = ['Gender', \n",
    "                'Marrital Status',\n",
    "                'Num. Dependents',\n",
    "                'Education', \n",
    "                'Employment Type', \n",
    "                'Applicant Income', \n",
    "                'Co-Applicant Income', \n",
    "                'Loan Amount', \n",
    "                'Loan Duration', \n",
    "                'Credit History Status', \n",
    "                'Property Area Type', \n",
    "                'Application Status']\n",
    "\n",
    "orig_dataset.columns = pretty_names\n",
    "\n",
    "target_feat_id = 'Application Status'\n",
    "\n",
    "orig_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify label names for categorical feature values\n",
    "\n",
    "# 'Marrital Status'\n",
    "print(orig_dataset['Employment Type'].unique())\n",
    "orig_dataset.loc[:, ['Employment Type']] = orig_dataset['Employment Type'].apply(lambda x: 'Self-Employed' if x == 'Yes' else 'Not Self-Employed' if x == 'No' else x)\n",
    "print(orig_dataset['Employment Type'].unique())\n",
    "print()\n",
    "\n",
    "# 'Marrital Status'\n",
    "print(orig_dataset['Marrital Status'].unique())\n",
    "orig_dataset.loc[:, ['Marrital Status']] = orig_dataset['Marrital Status'].apply(lambda x: 'Married' if x == 'Yes' else 'Unmarried' if x == 'No' else x)\n",
    "print(orig_dataset['Marrital Status'].unique())\n",
    "print()\n",
    "\n",
    "# 'Application Status'\n",
    "print(orig_dataset['Application Status'].unique())\n",
    "orig_dataset.loc[:, ['Application Status']] = orig_dataset['Application Status'].apply(lambda x: 'Approved' if x == 'Y' else 'Rejected' if x == 'N' else x)\n",
    "print(orig_dataset['Application Status'].unique())\n",
    "print()\n",
    "\n",
    "# 'Accesible Credit History'\n",
    "print(orig_dataset['Credit History Status'].unique())\n",
    "orig_dataset.loc[:, ['Credit History Status']] = orig_dataset['Credit History Status'].apply(lambda x: 'Available' if x == 1 else 'Unavailable' if x == 0 else x)\n",
    "print(orig_dataset['Credit History Status'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi column data encoder class\n",
    "\n",
    "# Required since sklearns default encoder cannot decode on multiple columns\n",
    "# Adapted from code courtesy of user gereleth on stack overflow\n",
    "# (source: https://stackoverflow.com/questions/58217005/how-to-reverse-label-encoder-from-sklearn-for-multiple-columns)\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoders = {}\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            self.encoders[col] = LabelEncoder().fit(X[col])\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        output = X.copy()\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            output[col] = self.encoders[col].transform(X[col])\n",
    "        return output\n",
    "\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        output = X.copy()\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            output[col] = self.encoders[col].inverse_transform(X[col])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical data\n",
    "\n",
    "dataset = deepcopy(orig_dataset)\n",
    "\n",
    "# List of categorical features to encode (as integers starting from 0)\n",
    "label_encode = ['Gender', \n",
    "                'Marrital Status',\n",
    "                'Num. Dependents',\n",
    "                'Education', \n",
    "                'Employment Type',\n",
    "                'Credit History Status', \n",
    "                'Property Area Type', \n",
    "                'Application Status']\n",
    "\n",
    "le = MultiColumnLabelEncoder(columns=label_encode)\n",
    "\n",
    "dataset = le.fit_transform(dataset)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test/train split for Model Training\n",
    "\n",
    "X = dataset.drop(columns=[target_feat_id]).values\n",
    "y = dataset[target_feat_id]\n",
    "\n",
    "test_size = 0.3\n",
    "random_state = 0\n",
    "\n",
    "# Parameter random_state=0 ensures the version of the model is identical to the one used in the project. Feel free to change this. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL\n",
    "## Create and train SKLearn random forrest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "untrained_model = sklearn.ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "model = untrained_model.fit(X_train, y_train.astype('int'))\n",
    "\n",
    "# Display classifier metrics\n",
    "y_pred = [lab for lab in model.predict(X_test)]\n",
    "\n",
    "test_class = [np.int64(z) for z in y_test.values]\n",
    "\n",
    "report = classification_report(test_class, y_pred)\n",
    "print('\\n' + report)\n",
    "accuracy = accuracy_score(test_class, y_pred)\n",
    "print('Accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA INSTANCE\n",
    "## Select data instance and compute feature attributions of SHAP LIME and GAM libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data instance\n",
    "data_instance_index = 62\n",
    "data_instance = np.array(dataset.loc[data_instance_index])[:-1]\n",
    "data_instance_orig_labels = orig_dataset.loc[data_instance_index]\n",
    "\n",
    "# print(X_test[13])\n",
    "print(data_instance)\n",
    "print(data_instance_orig_labels)\n",
    "\n",
    "# Create df to hold attribution results for each method and composites\n",
    "feature_names = dataset.drop(columns=[target_feat_id]).columns\n",
    "\n",
    "attributions = pd.DataFrame(columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute LIME attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of indices (ints) corresponding to the categorical columns. Everything else will be considered continuous\n",
    "categorical_feature_indecies =  [0, 1, 2, 3, 4, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train,\n",
    "                                                   feature_names=list(feature_names), \n",
    "                                                   categorical_features=categorical_feature_indecies, \n",
    "                                                   verbose=True,\n",
    "                                                   mode='classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(data_instance, model.predict_proba, num_features=len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from lime representations to feature names\n",
    "lime_attr = {}\n",
    "\n",
    "# WARNING: Features who's names appear as substrings of names of other features break this code\n",
    "for feat in exp.as_list():\n",
    "    for f_name in list(feature_names):\n",
    "        if(f_name in feat[0]):\n",
    "            lime_attr[f_name] = feat[1]\n",
    "            \n",
    "lime_attr = pd.Series(lime_attr)\n",
    "lime_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record lime attributions\n",
    "lime_attr.name = 'LIME'\n",
    "\n",
    "attributions = attributions.append(lime_attr)\n",
    "\n",
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise lime attributions\n",
    "# %matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SHAP attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.DataFrame(np.array([data_instance]), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(\n",
    "    pd.DataFrame(np.array([data_instance]), \n",
    "                 columns=feature_names))\n",
    "\n",
    "# Select appropriate set of shap values based on model prediction\n",
    "shap_values = shap_values[model.predict([data_instance])[0]]\n",
    "\n",
    "shap_values\n",
    "            \n",
    "#shap_values\n",
    "# \n",
    "# shap.plots.force(shap_values)\n",
    "# dict(pd.Series(shap_values, index=feature_names))\n",
    "# dictionary = dict(zip(shap_values, feature_names))\n",
    "# \n",
    "# shap.plots.bar({A: B for A, B in zip(feature_names, shap_values)})\n",
    "# shap.plots.bar(dict(pd.Series(list(shap_values[0]), index=feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record shap attributions\n",
    "\n",
    "# list(shap_values[0])\n",
    "\n",
    "shap_attr = pd.Series(list(shap_values[0]), index=feature_names)\n",
    "\n",
    "\n",
    "shap_attr.name = 'SHAP'\n",
    "\n",
    "#shap_attr\n",
    "attributions = attributions.append(shap_attr)\n",
    "\n",
    "type(attributions.index)\n",
    "\n",
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train general linear model for alternative global attribution estimator\n",
    "### (this is disabled by default but can be enabled as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Since we are explaining model, run regression on model predictions\n",
    "\n",
    "# Warning, note that here we are using variable encodings as dummy variables, depending on feature semantics this may not be optimal\n",
    "\n",
    "X_all = dataset.drop(columns=[target_feat_id]).to_numpy()\n",
    "\n",
    "Y_all = model.predict(X_all)\n",
    "\n",
    "regr.fit(X_all, Y_all)\n",
    "\n",
    "print(regr.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_attr = pd.Series(list(regr.coef_), index=feature_names)\n",
    "\n",
    "regr_attr.name = 'GLOBAL REGRESSION'\n",
    "\n",
    "# attributions = attributions.append(regr_attr)\n",
    "\n",
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE COUNTERFACTUAL/S\n",
    "## Using Dice-ML (Based on https://arxiv.org/abs/1905.07697)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that can vary in counterfactual examples\n",
    "# 'Marrital Status', 'Num. Dependents'?\n",
    "\n",
    "features_to_vary = ['Education', \n",
    "                    'Employment Type', \n",
    "                    'Applicant Income', \n",
    "                    'Co-Applicant Income',  \n",
    "                    'Loan Duration',\n",
    "                    'Credit History Status', \n",
    "                    'Property Area Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap objects for use with dice\n",
    "dice_data = dice_ml.Data(dataframe=dataset,\n",
    "                 continuous_features=[x for x in dataset.columns if x not in label_encode],\n",
    "                 outcome_name=target_feat_id)\n",
    "\n",
    "dice_model = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "\n",
    "# KD-Tree finds counterfactuals within the dataset\n",
    "# This is good since we are working with a rather innacurate model and small dataset\n",
    "# resulting in randomly sampled counterfactuals being erratic\n",
    "\n",
    "# dice_exp = dice_ml.Dice(dice_data, dice_model, method='kdtree')\n",
    "\n",
    "dice_exp = dice_ml.Dice(dice_data, dice_model)\n",
    "dice_instance = pd.DataFrame([data_instance], columns=feature_names)\n",
    "\n",
    "# Generate counterfactuals\n",
    "counterfactual = dice_exp.generate_counterfactuals(dice_instance, \n",
    "                                                   total_CFs=1, \n",
    "                                                   desired_class=\"opposite\",\n",
    "                                                   features_to_vary=features_to_vary)\n",
    "\n",
    "# features_to_vary= //// Features to vary\n",
    "# feature_weights=feature_weights /// Dict of feature weithgts\n",
    "\n",
    "counterfactual.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "# Through minor surgery we can obtain counterfactuals as a dataframe\n",
    "counterfactual = counterfactual.cf_examples_list[0].final_cfs_df\n",
    "\n",
    "counterfactual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Load counterfactuals for reproducability\n",
    "\n",
    "# This line can be uncommented to save newly generated counterfactuals\n",
    "# counterfactual.to_csv('survey/counter_fact/counterfactuals_save.csv')\n",
    "\n",
    "# By default, this file contains counterfactual examples used in the study\n",
    "counterfactual = pd.read_csv('survey/counter_fact/counterfactuals_load.csv')\n",
    "\n",
    "counterfactual = counterfactual.reset_index(drop=True)\n",
    "\n",
    "counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode feature encodings for newly generated counterfactual example\n",
    "\n",
    "# Fix column dtypes\n",
    "counterfactual[label_encode] = counterfactual[label_encode].astype(int)\n",
    "\n",
    "decoded_counterfactuals = le.inverse_transform(counterfactual)\n",
    "# decoded_counterfactuals = le.inverse_transform(orig_)\n",
    "\n",
    "decoded_counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate attributions using DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dice attributions from set of counterfactuals\n",
    "imp = dice_exp.local_feature_importance(dice_instance, total_CFs=50)\n",
    "\n",
    "print(imp.local_importance[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dice attributions\n",
    "\n",
    "dice_attr = pd.Series(imp.local_importance[0].values(), index=feature_names)\n",
    "\n",
    "dice_attr.name = 'DICE-ML'\n",
    "\n",
    "#shap_attr\n",
    "attributions = attributions.append(dice_attr)\n",
    "\n",
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALISE ATTRIBUTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Express attributions as percentage of the sum of the absolute value of each attribution\n",
    "# This is done so that they can be presented on a common axis.\n",
    "\n",
    "for index, row in attributions.iterrows():\n",
    "    scale = row.abs().sum()\n",
    "    row.update(row.apply(lambda x : x * 100 / scale))\n",
    "\n",
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE COMPOSITE SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_scores = {}\n",
    "for col in attributions:\n",
    "    composite_scores[col] = np.mean(attributions[col])\n",
    "\n",
    "composite_scores = pd.Series(composite_scores)\n",
    "composite_scores.name = 'COMPOSITE'\n",
    "\n",
    "#shap_attr\n",
    "attributions = attributions.append(composite_scores)\n",
    "\n",
    "attributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE TEXT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Jinja2 templates for NLG\n",
    "\n",
    "APP_OUT = \"loan_approval_outcome.txt\"\n",
    "BASE_EXP = \"base_textual_explanation.txt\"\n",
    "COUNTER = \"textual_counterfactual.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "templateLoader = FileSystemLoader(searchpath=\"./templates\")\n",
    "templateEnv = Environment(loader=templateLoader)\n",
    "\n",
    "# Load templates\n",
    "temp_app_outcome = templateEnv.get_template(APP_OUT)\n",
    "temp_base_exp = templateEnv.get_template(BASE_EXP)\n",
    "temp_counterfact = templateEnv.get_template(COUNTER)\n",
    "\n",
    "temp_app_outcome.render(acceptance='Hello World!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTRUCT EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 35}\n",
    "\n",
    "rc('font', **font)\n",
    "rc('text',usetex=True)\n",
    "rc('text.latex', preamble=r'\\usepackage{color}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure to store data needed to generate explanation unrelated to explanation settings/layers\n",
    "\n",
    "@dataclass\n",
    "class PublicData:\n",
    "    # Pandas dataframe of counterfactual explanations\n",
    "    counterfactuals : pd.DataFrame\n",
    "    \n",
    "    # Pandas dataframe of feature attributions\n",
    "    attributions : pd.DataFrame\n",
    "        \n",
    "    # Feature values of explanation instance\n",
    "    feature_values : pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise explanation data\n",
    "\n",
    "pub_data = PublicData(\n",
    "    counterfactuals=decoded_counterfactuals,\n",
    "    attributions=attributions,\n",
    "    feature_values = data_instance_orig_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for cleaning data before display\n",
    "\n",
    "def add_units(features):\n",
    "    features = deepcopy(features)\n",
    "    # Add units to select features and remove decimal places\n",
    "    # features <-- pandas series of feature values\n",
    "    features['Applicant Income'] = str(int(features['Applicant Income'])) + ' \\$/Mo'\n",
    "    features['Co-Applicant Income'] = str(int(features['Co-Applicant Income'])) + ' \\$/Mo'\n",
    "    features['Loan Amount'] = str(int(features['Loan Amount'])) + '000 \\$'\n",
    "    features['Loan Duration'] = str(int(features['Loan Duration'])) + ' Months'\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(add_units(pub_data.feature_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_explanation(pub_data, visualise=False, num_feats=2, display_min=False, display_composite=True, display_counterfactuals=False):\n",
    "    '''\n",
    "    Method to generate arbitrary explanation from configuration space.\n",
    "    \n",
    "    The parameters are as follows:\n",
    "    visualise <-- Weather to display explanations as text or visualise as plots\n",
    "    attributions <-- pandas dataframe containing normalised attributions of each model and composite attribution scores\n",
    "    num_feats <-- number of features to display (display the num_feats top positive contributors according to composite scores).\n",
    "                  if Set to 0, all featueres are displayed\n",
    "    display_min <-- If true, display num_feats least (highest negatively) contributing features aswell\n",
    "    display_composite <-- if true, display composite scores instead of individual models' attributions\n",
    "    '''\n",
    "    \n",
    "    if visualise:\n",
    "        plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    \n",
    "    # Easier to run notebook cells asyncronously\n",
    "    pub_data = deepcopy(pub_data)\n",
    "    attributions = pub_data.attributions\n",
    "    \n",
    "    # Preprocess feature names\n",
    "    for ind, row in pub_data.counterfactuals.iterrows():\n",
    "        pub_data.counterfactuals.loc[ind] = add_units(pub_data.counterfactuals.loc[ind])\n",
    "    \n",
    "    pub_data.feature_values = add_units(pub_data.feature_values)\n",
    "    \n",
    "    if num_feats == 0:\n",
    "        num_feats = len(attributions.columns)\n",
    "    # Construct plot\n",
    "    \n",
    "    # Number of grid cells for table of counterfactuals to take up\n",
    "    cellspertable = int(len(attributions.columns) / 2)\n",
    "    \n",
    "    # Number of grid cells for plot of single counterfactual to take up\n",
    "    cellsperplot = 1\n",
    "    \n",
    "    # One for each feature/counterfactual and one for text\n",
    "    if visualise:\n",
    "        numfigs = num_feats * cellsperplot + 2\n",
    "    else: \n",
    "        numfigs = ((num_feats+1)//2)\n",
    "    \n",
    "    if display_counterfactuals:\n",
    "        numfigs += (cellspertable * len(pub_data.counterfactuals.index) + 1)\n",
    "    \n",
    "    # plt.rcParams['figure.figsize'] = [20, 3 * numfigs]\n",
    "    \n",
    "    fig = plt.figure(figsize=(21, 3 * numfigs))\n",
    "    gs = gridspec.GridSpec(nrows=numfigs, ncols=2,\n",
    "                        hspace=1, figure=fig)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    # Track y displacement in grid\n",
    "    curr_figure = 0\n",
    "\n",
    "    \n",
    "    ###################### Textual explanation of classifier attributions ######################\n",
    "    if not visualise:\n",
    "        class_text_box = fig.add_subplot(gs[curr_figure:curr_figure + max((num_feats // 5), 1), :])\n",
    "        curr_figure += max(((num_feats) // 5), 1)\n",
    "\n",
    "        ordered_feats = list(reversed(pub_data.attributions.loc[\"COMPOSITE\"].sort_values().index))\n",
    "\n",
    "        text = temp_app_outcome.render(acceptance=pub_data.feature_values['Application Status'])\n",
    "        text += temp_base_exp.render(num_feats=num_feats, \n",
    "                                    feature_vals=pub_data.feature_values,\n",
    "                                   feats_by_contrib=ordered_feats,\n",
    "                                    attributions=attributions.loc['COMPOSITE'],\n",
    "                                    ordinals=[num2words(i, to=\"ordinal_num\") for i in range(num_feats + 1)])\n",
    "\n",
    "        class_text_box.text(-0.1, 1, text, wrap=True, linespacing=0.5)\n",
    "        class_text_box.axis(\"off\")\n",
    "    \n",
    "    ###################### Feature attribution plots ######################\n",
    "    \n",
    "    if visualise:\n",
    "        class_text_box = fig.add_subplot(gs[curr_figure, :])\n",
    "        curr_figure += 1\n",
    "    \n",
    "        text = temp_app_outcome.render(acceptance=pub_data.feature_values['Application Status'])\n",
    "\n",
    "        class_text_box.text(-0.1, 1, text, wrap=True)\n",
    "        class_text_box.axis(\"off\")\n",
    "    \n",
    "        fp_text_box = fig.add_subplot(gs[curr_figure, :])\n",
    "        curr_figure += 1\n",
    "\n",
    "        # text explaining plots\n",
    "        if num_feats == len(attributions.columns):\n",
    "                text = \"\"\"The following are the scores attributed to your application's features listed in order of importance:\"\"\"\n",
    "        else:\n",
    "            if display_min:\n",
    "                text = \"The following are the scores attributed to the \" + str(num_feats) + \"\"\" features \n",
    "                of your application that contributed most/least to the classifier's decision: \"\"\"\n",
    "            else:\n",
    "                if num_feats == 1:\n",
    "                    text = \"The following is the score attributed to the most imoportant feature of your application:\"\n",
    "                else:\n",
    "                    text = \"The following are the scores attributed to the \" + str(num_feats) + \"\"\" most imoportant features of your application:\"\"\"\n",
    "\n",
    "        fp_text_box.text(-0.1, 0.5, text, wrap=True)\n",
    "        fp_text_box.axis(\"off\")\n",
    "\n",
    "\n",
    "        # Deide on common axis\n",
    "        x_max = max([abs(max(attributions.max(axis=1))), \n",
    "                     abs(min(attributions.min(axis=1)))])\n",
    "\n",
    "        xlim=(-1.1 *x_max, 1.1 * x_max)\n",
    "\n",
    "        for i in range(num_feats):\n",
    "            # find i-th most/least salient feature (by composite)\n",
    "            feat_max = attributions.loc['COMPOSITE'].idxmax(axis=0)\n",
    "            feat_min = attributions.loc['COMPOSITE'].idxmin(axis=0)\n",
    "\n",
    "            if(display_composite):\n",
    "                y_lab = ['SCORE']\n",
    "                max_w = (attributions.loc['COMPOSITE'])[feat_max]\n",
    "                min_w = (attributions.loc['COMPOSITE'])[feat_min]\n",
    "            else:\n",
    "                y_lab = list((pub_data.attributions.drop(['COMPOSITE'], axis=0)).index)\n",
    "                max_w = [(attributions.loc[attr])[feat_max] for attr in y_lab]\n",
    "                min_w = [(attributions.loc[attr])[feat_min] for attr in y_lab]\n",
    "\n",
    "            # Plot i-th most/least salient feature\n",
    "\n",
    "            colors_max = cm.autumn( [(1.0 / (i+1)) for i in range(len(y_lab))])\n",
    "            colors_min = cm.winter( [(1.0 / (i+1)) for i in range(len(y_lab))])\n",
    "\n",
    "            if display_min:\n",
    "                axs1 = fig.add_subplot(gs[curr_figure : curr_figure + cellsperplot, 1])\n",
    "                axs1.barh(y_lab, min_w, align='center', height=0.3, color=['#FFC20A' if val > 0 else '#0C7BDC' for val in max_w])\n",
    "                axs1.set_xlim(xlim)\n",
    "                axs1.set_xlabel('\\% Of Total Feature Importance')\n",
    "                axs1.set_title('Contribution of ' + feat_min + ' = ' + str(pub_data.feature_values[feat_min]))\n",
    "                axs1.axvline(x=0, linewidth=1, color='k')\n",
    "\n",
    "                axs2 = fig.add_subplot(gs[curr_figure : curr_figure + cellsperplot, 0])\n",
    "                axs2.barh(y_lab, max_w, align='center', height=0.3, color=['#FFC20A' if val > 0 else '#0C7BDC' for val in min_w])\n",
    "                axs2.set_xlim(xlim)\n",
    "                axs1.xlabel('\\% Of Total Feature Importance')\n",
    "                axs2.set_title('Contribution of ' + feat_max + ' = ' + str(pub_data.feature_values[feat_max]))\n",
    "                axs2.axvline(x=0, linewidth=1, color='k')\n",
    "\n",
    "                # Remove features already displayed\n",
    "                attributions = attributions.drop(feat_max, axis=1)\n",
    "                attributions = attributions.drop(feat_min, axis=1)\n",
    "            else:\n",
    "                if type(max_w) != list:\n",
    "                    max_w = [max_w]\n",
    "                axs = fig.add_subplot(gs[curr_figure : curr_figure + cellsperplot, :])\n",
    "                axs.barh(y_lab, max_w, color=['#FFC20A' if val > 0 else '#0C7BDC' for val in max_w])\n",
    "                axs.set_xlim(xlim)\n",
    "                axs.set_title('Contributions of ' + feat_max + ' = ' + str(pub_data.feature_values[feat_max]))\n",
    "                axs.axvline(x=0, linewidth=1, color='k')\n",
    "                axs.set_xlabel('\\% Of Total Feature Importance')\n",
    "                \n",
    "                # Set bar labels\n",
    "                ind = 0\n",
    "                for i in axs.patches:\n",
    "                    # get_width pulls left or right; get_y pushes up or down\n",
    "                    axs.text(i.get_width()+.3, -1 * i.get_y(), \\\n",
    "                            str(round(max_w[ind], 2))+'%',\n",
    "                            color='black')\n",
    "                    \n",
    "                    ind += 1\n",
    "    \n",
    "                \n",
    "            attributions = attributions.drop(feat_max, axis=1)\n",
    "            curr_figure += cellsperplot\n",
    "\n",
    "    plt.rcParams['figure.constrained_layout.use'] = False\n",
    "    \n",
    "    if display_counterfactuals:\n",
    "        # Display counterfactual explanations\n",
    "        \n",
    "        # Add counterfactual text\n",
    "        text_box = fig.add_subplot(gs[curr_figure, :])\n",
    "        curr_figure += 1\n",
    "        \n",
    "        text = \"The following candidate profile/s similar to yours would have achieved the opposite outcome:\"\n",
    "        text_box.text(-0.1, 0.5, text, wrap=True)\n",
    "        text_box.axis(\"off\")\n",
    "        \n",
    "        cf_tables = []\n",
    "        for index, row in pub_data.counterfactuals.iterrows():\n",
    "            # Add table for each counterfactual explanation\n",
    "            cf_tables.append(fig.add_subplot(gs[curr_figure :  curr_figure + cellspertable, :]))\n",
    "            \n",
    "            curr_figure += cellspertable\n",
    "            \n",
    "            cell_colours = [[\"#ffd1dc\"] \n",
    "                            if row[attribute] != pub_data.feature_values[attribute] \n",
    "                            else [\"#ffffff\"]\n",
    "                            for attribute in row.index]\n",
    "\n",
    "            # cell_text = [[row[attribute]] for attribute in row.index]\n",
    "            cell_text = [[ '\\\\textbf{' + str(pub_data.feature_values[attribute]) + '$\\longrightarrow$ ' + str(row[attribute]) + '}']\n",
    "                          if row[attribute] != pub_data.feature_values[attribute] \n",
    "                          else ['\\\\textbf{' + str(row[attribute]) + '}'] \n",
    "                          for attribute in row.index]\n",
    "            \n",
    "            tab = cf_tables[index].table(cellText=cell_text,\n",
    "                                        rowLabels=['\\\\textbf{' + s + '}' for s in row.index],\n",
    "                                        colLabels=['\\\\textbf{Value}'],\n",
    "                                        loc=\"upper center\",\n",
    "                                        colWidths=[0.3],\n",
    "                                        cellColours=cell_colours)\n",
    "            \n",
    "            tab.scale(1, 5)\n",
    "            tab.set_fontsize(40)\n",
    "            cf_tables[index].axis(\"off\")\n",
    "            pass\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fig = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=1,\n",
    "                      display_composite=False,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "\n",
    "\n",
    "# plt.savefig('explanation.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render explanations to be used with experiments \n",
    "\n",
    "# This code can be uncommented for easy regeneration of plots\n",
    "'''\n",
    "text_few = construct_explanation(pub_data,\n",
    "                      visualise=False,\n",
    "                      num_feats=3,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "text_few.savefig('survey/text_few/explanation.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "chart_few = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=3,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "chart_few.savefig('survey/chart_few/explanation.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "\n",
    "chart_many = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=0,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "\n",
    "chart_many.savefig('survey/chart_many/explanation.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "\n",
    "chart_models = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=3,\n",
    "                      display_composite=False,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "chart_models.savefig('survey/chart_few_models/explanation.png', bbox_inches='tight', dpi=200)\n",
    "\n",
    "\n",
    "\n",
    "chart_count = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=3,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=True)\n",
    "chart_count.savefig('survey/chart_few_count/explanation.svg', bbox_inches='tight', dpi=200)\n",
    "'''\n",
    "# Feature Quantity explanations\n",
    "\n",
    "\n",
    "# CHART SINGLE\n",
    "'''\n",
    "\n",
    "example_fig = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=1,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "\n",
    "\n",
    "plt.savefig('single_charts.png', bbox_inches='tight')\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "# CHART FEW\n",
    "\n",
    "example_fig = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=3,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "\n",
    "\n",
    "plt.savefig('three_charts.png', bbox_inches='tight')\n",
    "'''\n",
    "\n",
    "# CHART ALL\n",
    "\n",
    "'''\n",
    "\n",
    "example_fig = construct_explanation(pub_data,\n",
    "                      visualise=True,\n",
    "                      num_feats=0,\n",
    "                      display_composite=True,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals=False)\n",
    "\n",
    "plt.savefig('eleven_charts.png', bbox_inches='tight', dpi=200)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display table of feature values\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5), dpi=300)\n",
    "\n",
    "cell_text = [[str(add_units(pub_data.feature_values)[attribute])] \n",
    "             for attribute in pub_data.feature_values.index]\n",
    "    \n",
    "f_value_table = plt.table(cellText=cell_text[:-1],\n",
    "          rowLabels=pub_data.feature_values.index[:-1],\n",
    "          colLabels=['Value'],\n",
    "          loc=\"upper center\",\n",
    "          colWidths=[0.3])\n",
    "\n",
    "f_value_table.scale(1, 3)\n",
    "f_value_table.fontsize = 16\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# plt.savefig('survey/data_instance/feature_values.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERACTIVE DISPLAY TOOL\n",
    "\n",
    "## An interactive widget that can be used to explore datapoints in the explanation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f(display_model_scores, display_all_features, display_counterfactuals, textual_attributions):\n",
    "    if display_all_features:\n",
    "        nf = 0\n",
    "    else:\n",
    "        nf = 3\n",
    "    fig = construct_explanation(pub_data,\n",
    "                      num_feats=nf,\n",
    "                      visualise=not textual_attributions,\n",
    "                      display_composite=not display_model_scores,\n",
    "                      display_min=False,\n",
    "                      display_counterfactuals= display_counterfactuals)\n",
    "    # fig.show()\n",
    "\n",
    "interactive_plot = interactive(f, display_model_scores=False, display_all_features=False, display_counterfactuals=False, textual_attributions=False)\n",
    "output = interactive_plot.children[-1]\n",
    "#output.layout.height = '2000px'\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
